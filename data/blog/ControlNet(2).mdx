---
title: ControlNet代码及模型结构详解（1）
date: '2023-11-22'
tags: ['diffusion','图像生成','controlNet']
summary: 自顶向下学习ControlNet的模型结构及代码
---

## 概述

- paper：https://arxiv.org/abs/2302.05543
- github：https://github.com/lllyasviel/ControlNet
- 通过语义图控制文本引导图像生成的过程来**自顶向下分析**ControlNet的采样过程，以了解其代码和模型结构，分为以下几部分：
  - 首先看采样脚本 gradio_seg.py，将模型及DDIM过程都当作一个黑盒，分析传入的各个参数的作用
  - 仍然将模型视作一个黑盒，只需要知道模型每次接收噪声图像x、时间步t、条件c，输出预估噪声，着重看DDIM的采样过程
  - 研究从配置文件加载模型的过程，以此来了解模型结构及其计算过程

- 前一篇分析了各个参数的作用，本篇继续将模型视作一个黑盒，着重分析DDIM的采样过程

## DDIM采样过程

-  主要由ddim_sampler 类实现， 位于 cldm/ddim_hacked.py 文件

### sample 方法

首先进入其 sample 方法，主要做了条件校验以及设置采样过程中用到的参数：

- 判断传入的cond数量（第0维大小）是否与 batch_size（n_samples）相等
- 设置一些调度信息，用于控制采样过程：
  - 通过传入的采样步数，设置对应数量的 timestep 值
  - todo 设置了其他一些DDIM采样参数
- 调用 self.ddim_sampling

### ddim_sampling 方法

- 首先采样一个随机噪声作为噪声图像：

```python
if x_T is None:
    img = torch.randn(shape, device=device)
else:
    img = x_T
```

- 接下来设置时间步：

```python
if timesteps is None:
  	# self.ddim_timesteps 为 make_schedule 方法根据传入的采样步数设置
    timesteps = self.ddpm_num_timesteps if ddim_use_original_steps else self.ddim_timesteps
elif timesteps is not None and not ddim_use_original_steps:
    subset_end = int(min(timesteps / self.ddim_timesteps.shape[0], 1) * self.ddim_timesteps.shape[0]) - 1
    timesteps = self.ddim_timesteps[:subset_end]
```

- 遍历 timesteps，每一次都调用 self.p_sample_ddim 对 batch 个输入进行一次消噪

### p_sample_ddim 方法

- 调用 ControlLDM 模型，传入 噪声图像x、时间步t、条件 c进行噪声估计。

```python
if unconditional_conditioning is None or unconditional_guidance_scale == 1.:
    model_output = self.model.apply_model(x, t, c)
else:
    model_t = self.model.apply_model(x, t, c)
    model_uncond = self.model.apply_model(x, t, unconditional_conditioning)
    model_output = model_uncond + unconditional_guidance_scale * (model_t - model_uncond)
```

- todo 根据前面设置的采样参数进行一系列计算

- 最终返回的就是通过unconditional_guidance_scale参数控制的模型的condition_output 和 uncondition_output的加权求和结果
